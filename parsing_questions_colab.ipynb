{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424c849f-e0e0-403f-a02a-2e3ebced6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR COLAB ONLY\n",
    "# from google.colab import drive\n",
    "# import pandas as pd\n",
    "\n",
    "# # Mounting file-system from drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Function to load files\n",
    "# def load_file(file_path):\n",
    "#   with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#     content = f.read()\n",
    "#   return content\n",
    "\n",
    "# # Logining in and authenticating hugging face account\n",
    "# !pip install -q huggingface_hub\n",
    "# from huggingface_hub import login\n",
    "# login(token=load_file('/content/drive/My Drive/work/cimatec/enade_to_edag/data/keys/hf') \\\n",
    "#     .strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc50653c-9270-4489-8f47-1aa050543c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import torch\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Initializing processor\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-large\", \\\n",
    "                                                apply_ocr=True, ocr_lang=\"por\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Function to extract questions from PDF\n",
    "def extract_questions_layout(pdf_path, dpi=300, visual=-1):\n",
    "# Converting PDF pages to PIL images\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "    pages = pages[1:-2]\n",
    "    \n",
    "    # Running LayoutLMv3 OCR\n",
    "    tokens = []\n",
    "    boxes = []\n",
    "    for i, page in enumerate(pages, start=1):\n",
    "        # Running model\n",
    "        enc = processor(page, return_tensors=\"pt\", truncation=True, \\\n",
    "        max_length=1024).to(device)\n",
    "        \n",
    "        # Extracting tokens and boundig boxes\n",
    "        page_tokens = enc.tokens()\n",
    "        page_tokens = [token.replace('Ä ', '') for token in page_tokens]\n",
    "        page_boxes  = enc.bbox.squeeze(0)\n",
    "        \n",
    "        tokens.append(page_tokens)\n",
    "        boxes.append(page_boxes)\n",
    "        \n",
    "        # Drawing bounding boxes on questions\n",
    "        if visual != -1 and i == visual:\n",
    "            orig_w, orig_h = page.size\n",
    "            draw = ImageDraw.Draw(page)\n",
    "            for idx in range(len(page_tokens)):\n",
    "                x0, y0, x1, y1 = page_boxes[idx]\n",
    "                draw.rectangle([(orig_w*x0/1000, orig_h*y0/1000), \\\n",
    "                                (orig_w*x1/1000, orig_h*y1/1000)], \\\n",
    "                               outline=\"red\", width=2)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.imshow(page)\n",
    "\n",
    "            return pages, tokens, boxes\n",
    "    \n",
    "    return pages, tokens, boxes\n",
    "\n",
    "# Calling function\n",
    "pages, tokens, boxes = extract_questions_layout(\"data/enade_2023.pdf\", visual=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d5b0337-e734-4c8e-a52d-235d629e8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving screenshot of question for later usage on an LLM\n",
    "page_overflow = False\n",
    "prev = {'left': None, \"right\": None, \"discursiva\": None}\n",
    "open_counter = 1\n",
    "closed_counter = 1\n",
    "for i, t in enumerate(tokens):\n",
    "    # Getting indices of questions on a page\n",
    "    indices = [j for j, token in enumerate(t) if token == 'QUEST']\n",
    "\n",
    "    # Saving continuation of a question on another second page\n",
    "    if page_overflow is True:\n",
    "        try:\n",
    "            bot_limit = boxes[i][indices[0], 1]\n",
    "        except:\n",
    "            bot_limit = torch.max(boxes[i][:-1, 1])\n",
    "        \n",
    "        img = pages[i]\n",
    "        orig_w, orig_h = img.size\n",
    "        left = (prev[\"left\"].item()/1000)*orig_w - 5\n",
    "        right = (prev[\"right\"].item()/1000)* orig_w + 5\n",
    "        top = 5\n",
    "        bottom = (bot_limit.item()/1000)*orig_h + 5\n",
    "\n",
    "        crop = img.crop((left, top, right, bottom))\n",
    "        if discursiva:\n",
    "            fname = f\"data/visual_approach/open_question_{open_counter-1:02d}_p2.png\"\n",
    "        else:\n",
    "            fname = f\"data/visual_approach/closed_question_{closed_counter-1:02d}_p2.png\"\n",
    "        crop.save(fname)\n",
    "        \n",
    "        page_overflow = False\n",
    "\n",
    "    # Going through questions on a page\n",
    "    for j, idx in enumerate(indices):\n",
    "        # Checking if its closed or open\n",
    "        discursiva = (t[idx+3] == 'DIS')\n",
    "\n",
    "        # Computing limits for cropping\n",
    "        left_limit, right_limit = boxes[i][idx, 0], torch.max(boxes[i][:-1, 2])\n",
    "        top_limit = boxes[i][idx, 1]\n",
    "        \n",
    "        # Two questions on the same page\n",
    "        if j < len(indices)-1:\n",
    "            bot_limit = boxes[i][indices[j+1], 1]\n",
    "        \n",
    "        # A question that either finishes the page or goes to another page\n",
    "        else:\n",
    "            page_overflow = True\n",
    "            bot_limit = boxes[i][-10, 3]\n",
    "\n",
    "        # Saving question\n",
    "        img = pages[i]\n",
    "        orig_w, orig_h = img.size\n",
    "        left = (left_limit.item()/1000)*orig_w - 5\n",
    "        right = (right_limit.item()/1000)* orig_w + 5\n",
    "        top = (top_limit.item()/1000)*orig_h - 5\n",
    "        bottom = (bot_limit.item()/1000)*orig_h + 5\n",
    "\n",
    "        crop = img.crop((left, top, right, bottom))\n",
    "        if discursiva:\n",
    "            fname = f\"data/visual_approach/open_question_{open_counter:02d}_p1.png\"\n",
    "            open_counter += 1\n",
    "        else:\n",
    "            fname = f\"data/visual_approach/closed_question_{closed_counter:02d}_p1.png\"\n",
    "            closed_counter += 1\n",
    "        crop.save(fname)\n",
    "\n",
    "        # Updating previous dictionary if needed\n",
    "        if page_overflow:\n",
    "            prev.update({\"left\": left_limit, \"right\": right_limit, \\\n",
    "                         \"discursiva\": discursiva})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c895302-77eb-43d3-bed5-4c89453daad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# \"Glueing\" multiple page questions\n",
    "folder = \"data/visual_approach\"\n",
    "open_pattern = re.compile(r\"open_question_(\\d{2})_p[12]\\.png$\")\n",
    "closed_pattern = re.compile(r\"closed_question_(\\d{2})_p[12]\\.png$\")\n",
    "\n",
    "# Gathering all files and group by question number\n",
    "groups = {}\n",
    "for fname in os.listdir(folder):\n",
    "    open_m = open_pattern.match(fname)\n",
    "    closed_m = closed_pattern.match(fname)\n",
    "    \n",
    "    if open_m:\n",
    "        qnum = open_m.group(1)\n",
    "        try:\n",
    "            groups[f'open_{qnum}'].append(fname)\n",
    "        except:\n",
    "            groups[f'open_{qnum}'] = [fname]\n",
    "\n",
    "    elif closed_m:\n",
    "        qnum = closed_m.group(1)\n",
    "        try:\n",
    "            groups[f'closed_{qnum}'].append(fname)\n",
    "        except:\n",
    "            groups[f'closed_{qnum}'] = [fname]\n",
    "\n",
    "# Stacking images vertically when question has more than one part\n",
    "for qnum, fnames in groups.items():\n",
    "    if len(fnames) < 2:\n",
    "        path = os.path.join(folder, fnames[0])\n",
    "        os.rename(path, os.path.join(folder, f\"{fnames[0].split('_p')[0]}.png\"))\n",
    "        continue\n",
    "\n",
    "    # Organizing order to stack correctly\n",
    "    fnames_sorted = sorted(fnames)\n",
    "\n",
    "    # Computing dimensions for the new canvas\n",
    "    imgs = [Image.open(os.path.join(folder, f)) for f in fnames_sorted]\n",
    "    widths, heights = zip(*(im.size for im in imgs))\n",
    "    max_width = max(widths)\n",
    "    total_height = sum(heights)\n",
    "\n",
    "    # Creating a blank canvas and pasting each part\n",
    "    combined = Image.new(\"RGB\", (max_width, total_height), (255, 255, 255))\n",
    "    y_offset = 0\n",
    "    for im in imgs:\n",
    "        combined.paste(im, (0, y_offset))\n",
    "        y_offset += im.height\n",
    "\n",
    "    # Saving the stacked image\n",
    "    combined.save(os.path.join(folder, f\"{fnames[0].split('_p')[0]}.png\"))\n",
    "\n",
    "    # Deleting the old files with parts\n",
    "    for f in fnames:\n",
    "        os.remove(os.path.join(folder, f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
