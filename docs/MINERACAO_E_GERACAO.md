## Overview

Nessa seção, descreveremos o processo de mineração dos dados, bem como a cricao do banco e dados usado pela plataforma, o processo de geracao de novas questões e como é possível replicar o processo para outros áreas do ENADE, facilitando a criação de novas questões de prova no estilo ENADE para professores e instituições, mas também para o prórpio uso de alunos no processo de estudo e preparo para essas provas.

## Mineração

Para essa parte inicial do projeto, a ideia era construir um banco de dados. Basicamente ter acesso a todas as informações necessárias para que pudéssemos seguir a diante na geracao de questões e, posteriormente, na análise histórica da prova. Para tal, um script de mineração de conteúdo do ENADE foi desenvolvido `py_scripts/enade_content_mining.py`.

### Mineração dos Editais

A ideia foi utilizar o chromium para simular computacionalmente interações de usuário na página tanto dos editais como das provas do enade. Uma vez nessas páginas, a máquina também simula clicks nos anos de prova e, em seguida, clicks nas páginas ou PDFs de editais/exames. Como há consistência no uso de certos termos (como computação), ainda que haja desorganização e inconsistência como em alguns anos o curso tenha sido chamado de engenharia de compuação enquanto em outros engenharia da computação, foi fácil desenvolver um padrão para clicks, apenas utilizando parsing de HTML diretamente do chromium ou com beautiful soup para procurar os links correspondentes. A extração dos editais em si, no entanto, é onde começa o desafio.

Alguns diferentes padrões tiveram que ser desenvolvidos, uma vez que editais de anos diferentes seguiam diferentes diretrizes. Para o ano de 2023, o edital estava em formato HTML, enquanto par os anos anteriores, o edital era um PDF, digitalização de um pedaço do diário oficial. A quantidade de tópicos e a ordem dos tópicos também variava em diferentes provas, dificultando o processo de simplesmente chegar num certo tópico do edital e extrair os conteúdos de lá. Alguns desses processos foram hard-coded, o que basicamente significa que tive que determinar intervalos para certos padrões (antes de 2017, o edital era assim, depois, entre 2020 e 2017, ficou dessa outra forma, e assim por diante). Mesmo o conteúdo em si muda durante o passar dos anos e a forma de anunciá-los também. No edital de 2023, por exemplo, não se encontram mais os conteúdos "comuns" na lista de conteúdos, como dos anos de 2019 para trás. Agora o edital nos permite extrair sistematicamente apenas os conteúdos específicos da engenharia selcionada.

Uma vez identificados todos os pontos, intervalos e padrões, o parsing do conteúdo pertencente a cada prova foi feito com chromuum e beautiful soup para editais em HTML e com fitz para editais em PDF. Terminada essa etapa inicial, criei um dicionário (que virá a ser um CSV mais tarde) com o curso detectado, os anos de prova e os conteúdo teóricos extraídos de cada prova. Apesar do estudo de caso para engenharia da computação, vale notar que o processo é absolutamente replicável para qualquer outra engenharia (com poucas modificações no código), e para outros cursos de forma geral (com um pouco mais de modificação e curadoria para entender as diferenças, mas com o código base já pronto), o que nos permite futuramente expandir o projeto para outros departamentos e facilitar a vida de próximas pessoas que queiram usufruir d'um produto semelhante para uso próprio.

### Mineração das provas

Essa parte foi bastante mais difícil de fazer funcionar. O parsind das provas foi uma etapa complicada que envolveu altos e baixos, tendo que adaptar metodologias para o seu pleno funcionamento. Todas as provas estão em PDF e o processo de adquirí-las foi bastante parecido com o anteriro, utilizando chromium para simular interações no website do ENADE e baixar os PDFs. O problema foi a leitura das provas.

A primeira abordagem, foi a utilização do pytesseract como extrator de conteúdo da prova. Essa abordagem, no entanto, falhou miseravelmente. O pytesseract para português não era capaz de compreender caracteres fora do alfabeto latino, o que representa um rpoblema severo em disciplinas nas exatas, uma vez que símbolos dos mais diversos são utilizados para representar variáveis, descrever equações e outros. Não só o pytesseract não compreendia esses símbolos, substituindo-os por caracteres aleatórios, como não era capaz de interpretar imagens, tabelas, diagramas e outros, que aparecem em diversas questões por todas as provas. Além disso, por conta da codificação do PDF, o pytesseract, por vezes, "lia" as páginas em ordens erradas, então nossa separação de questões (feita com uma busca gulosa pela próxima palavra 'questão') nem sempre funcionava e, mesmo quando funcionava, várias questões vinham com lacunas de símbolos que não conseguiram interpretar e sem asbilutamente nenhuma iamge ou diagrama.

Isso tudo já dentro dos PDFs para os quais alguma decodificação era possível. A prova de 2017, por exemplo, não foi compreendinda pelo pytesseract, sendo lida coma uma gigante string de símbolos aleatórios. Após muito tratamento e massagem nos dados para utilização do pytesseract, ficou claro que outra forma haveria de ser empregada para verídica compreensão das provas e seus conteúdos. Daí surge a ideia de usar um modelo moderno de alto desempenho na tarefa de Optical Character Recognition (OCR) e tratas os PDFs como grandes imagens a serem lidas por um modelo de OCR, e terem o seus textos tokenizados. Para tal, utilizamos um modelo open source da microsoft disponível no Hugging Face chamado microsoft/layoutlmv3-large.

## Geração

